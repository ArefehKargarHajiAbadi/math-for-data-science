{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b13e0d7-ff11-41a1-a809-3a8db00b37b7",
   "metadata": {},
   "source": [
    "# Random Vector\n",
    "\n",
    "## Objective Learning\n",
    "\n",
    "- Understand what **random vectors** are  \n",
    "- Learn about **joint PMF, CDF, and PDFs**  \n",
    "- Compute and interpret **covariance and correlation matrices**  \n",
    "- Differentiate between **uncorrelated** and **independent** random variables  \n",
    "- Understand **jointly normal** and **multivariate distributions**  \n",
    "- Explore **multinomial** and **Dirichlet** distributions  \n",
    "- Apply **Central Limit Theorem (CLT)** to multivariate data  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e4b26-6d42-4fcb-8a09-5bd0840ba738",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Definition](#Definition)  \n",
    "2. [Joint PMF](#JointPMF)  \n",
    "3. [Joint CDF](#JointCDF)  \n",
    "4. [Covariance Matrix](#CovarianceMatrix)  \n",
    "5. [Characteristics of Covariance Matrix](#CovMatrixCharacteristics)  \n",
    "6. [Correlation Matrix](#CorrelationMatrix)  \n",
    "7. [Cross Covariance Matrix](#CrossCovMatrix)  \n",
    "8. [Cross Correlation Matrix](#CrossCorrMatrix)  \n",
    "9. [Jointly Normal Random Variables](#JointlyNormal)  \n",
    "10. [Uncorrelated Random Variables](#UncorrelatedRVs)  \n",
    "11. [Independent Identically Distributed (i.i.d.) Variables](#IID)  \n",
    "12. [Central Limit Theorem (CLT)](#CLT)  \n",
    "13. [Multinomial Distribution](#Multinomial)  \n",
    "14. [Dirichlet Distribution](#Dirichlet)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d90bfe-df16-484a-9196-541769e88659",
   "metadata": {},
   "source": [
    "## 1. Definition <a name=\"Definition\"></a>\n",
    "\n",
    "A **random vector** is a vector of random variables:\n",
    "$$\n",
    "\\mathbf{X} = [X_1, X_2, ..., X_n]^T\n",
    "$$\n",
    "\n",
    "Each $X_i$ is a random variable.  \n",
    "We can represent multivariate data (e.g., height & weight) as a random vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898d3187-d3ad-4138-bafe-dec421e59a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.95099252, -0.90776692],\n",
       "       [ 0.39456696,  0.18504736],\n",
       "       [ 0.637566  ,  1.9986147 ],\n",
       "       [ 0.54805266, -0.1523023 ],\n",
       "       [-0.37731781, -0.61862094]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: 2D random vector\n",
    "X = np.random.normal(0, 1, 1000)\n",
    "Y = 0.5 * X + np.random.normal(0, 1, 1000)\n",
    "\n",
    "vector = np.vstack((X, Y)).T\n",
    "vector[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a1cba-809c-4e00-a146-60507613844c",
   "metadata": {},
   "source": [
    "## 2. Joint PMF <a name=\"JointPMF\"></a>\n",
    "\n",
    "For **discrete random variables**, the **Joint Probability Mass Function (PMF)** gives the probability of two variables taking specific values:\n",
    "\n",
    "$$\n",
    "P(X = x_i, Y = y_j)\n",
    "$$\n",
    "\n",
    "It describes the joint behavior of two discrete random variables.  \n",
    "The sum of all joint probabilities equals 1:\n",
    "\n",
    "$$\n",
    "\\sum_i \\sum_j P(X = x_i, Y = y_j) = 1\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Joint CDF <a name=\"JointCDF\"></a>\n",
    "\n",
    "The **Joint Cumulative Distribution Function (CDF)** gives the probability that two variables are simultaneously less than or equal to given values:\n",
    "\n",
    "$$\n",
    "F_{X,Y}(x, y) = P(X \\le x, \\, Y \\le y)\n",
    "$$\n",
    "\n",
    "It provides a complete description of the joint distribution for both **discrete** and **continuous** random variables.\n",
    "\n",
    "Properties:\n",
    "- $0 \\le F_{X,Y}(x, y) \\le 1$\n",
    "- Non-decreasing in both arguments\n",
    "- $\\lim_{x, y \\to \\infty} F_{X,Y}(x, y) = 1$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Covariance Matrix <a name=\"CovarianceMatrix\"></a>\n",
    "\n",
    "The **Covariance Matrix** measures the relationship between multiple random variables.  \n",
    "For a random vector $\\mathbf{X} = [X_1, X_2, ..., X_n]^T$, it is defined as:\n",
    "\n",
    "$$\n",
    "\\Sigma = E[(\\mathbf{X} - \\mu)(\\mathbf{X} - \\mu)^T]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\Sigma_{ii} = Var(X_i)$ (variance of each variable)\n",
    "- $\\Sigma_{ij} = Cov(X_i, X_j)$ (covariance between variables)\n",
    "\n",
    "Properties:\n",
    "- **Symmetric:** $\\Sigma = \\Sigma^T$\n",
    "- **Positive semi-definite:** $v^T \\Sigma v \\ge 0$ for all $v$\n",
    "- **Diagonal entries** show individual variances\n",
    "- **Off-diagonal entries** show how variables change together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0998d-5de1-4256-b768-2d5eabf2fb5c",
   "metadata": {},
   "source": [
    "## 5. Characteristics of Covariance Matrix <a name=\"CharacteristicsCovMatrix\"></a>\n",
    "\n",
    "The **covariance matrix** provides information about how each pair of random variables is related to each other. Here are the key characteristics:\n",
    "\n",
    "- **Symmetry**: The covariance matrix is always symmetric because $Cov(X_i, X_j) = Cov(X_j, X_i)$.\n",
    "- **Diagonal entries**: Represent the variances of the random variables.\n",
    "- **Off-diagonal entries**: Represent the covariances between pairs of random variables.\n",
    "\n",
    "For a **positive definite matrix**, all eigenvalues are positive, which implies that the variance in the system is always non-negative.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Correlation Matrix <a name=\"CorrelationMatrix\"></a>\n",
    "\n",
    "The **Correlation Matrix** is a normalized form of the covariance matrix. It measures the strength of the linear relationship between the variables.\n",
    "\n",
    "The elements of the correlation matrix are given by:\n",
    "\n",
    "$$\n",
    "\\rho_{ij} = \\frac{Cov(X_i, X_j)}{\\sqrt{Var(X_i)Var(X_j)}}\n",
    "$$\n",
    "\n",
    "Properties:\n",
    "- Diagonal entries are always 1 (the correlation of a variable with itself is always 1).\n",
    "- The range of values for off-diagonal entries is between -1 and 1, where:\n",
    "  - 1 indicates perfect positive linear correlation.\n",
    "  - -1 indicates perfect negative linear correlation.\n",
    "  - 0 indicates no linear correlation.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Cross Covariance and Correlation Matrices <a name=\"CrossCovCor\"></a>\n",
    "\n",
    "**Cross Covariance Matrix** measures the covariance between two sets of random variables (e.g., $\\mathbf{X}$ and $\\mathbf{Y}$):\n",
    "\n",
    "$$\n",
    "\\Sigma_{XY} = E[(\\mathbf{X} - \\mu_X)(\\mathbf{Y} - \\mu_Y)^T]\n",
    "$$\n",
    "\n",
    "**Cross Correlation Matrix** normalizes the cross covariance matrix, providing the relationship between the two sets of variables:\n",
    "\n",
    "$$\n",
    "\\rho_{XY} = \\frac{\\Sigma_{XY}}{\\sqrt{\\Sigma_X \\Sigma_Y}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Jointly Normal Random Variables <a name=\"JointlyNormal\"></a>\n",
    "\n",
    "A set of random variables is said to be **jointly normal** if every linear combination of these variables is also normally distributed.\n",
    "\n",
    "For a **jointly normal** distribution:\n",
    "- The **covariance matrix** defines the shape of the joint distribution.\n",
    "- The **marginal distributions** of the individual variables are also normal.\n",
    "\n",
    "---\n",
    "## 9. Independent and Identically Distributed (i.i.d.) <a name=\"IID\"></a>\r\n",
    "\r\n",
    "**Independent and Identically Distributed** (i.i.d.) random variables are those that are both:\r\n",
    "- **Independent**: The occurrence of one does not affect the probability of another.\r\n",
    "- **Identically Distributed**: All variables follow the same probability distribution.\r\n",
    "\r\n",
    "For example, if we have a set of independent coin flips, each flip is i.i.d., meaning each flip is independent and has the same probability distribution (50% heads, 50% tails).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 10. Central Limit Theorem (CLT) <a name=\"CLT\"></a>\r\n",
    "\r\n",
    "The **Central Limit Theorem (CLT)** states that the distribution of the sum (or average) of a large number of independent, identically distributed random variables approaches a **normal distribution** as the number of variables increases, regardless of the original distribution.\r\n",
    "\r\n",
    "Mathematically:\r\n",
    "\r\n",
    "$$\r\n",
    "\\lim_{n \\to \\infty} \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0, 1)\r\n",
    "$$\r\n",
    "\r\n",
    "Where:\r\n",
    "- $\\bar{X}$ is the sample mean\r\n",
    "- $\\mu$ is the population mean\r\n",
    "- $\\sigma$ is the population standard deviation\r\n",
    "\r\n",
    "The CLT is fundamental in statistics because it allows us to use normal distribution approximations for large sample sizes, even if the original data is not normally distributed.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 11. Normal Distribution <a name=\"NormalDistribution\"></a>\r\n",
    "\r\n",
    "The **Normal Distribution** (also called the Gaussian distribution) is the most widely used probability distribution in statistics. It is characterized by the **bell-shaped curve**, and is defined by two parameters:\r\n",
    "- **Mean** ($\\mu$)\r\n",
    "- **Variance** ($\\sigma^2$)\r\n",
    "\r\n",
    "The probability density function (PDF) of a normal distribution is:\r\n",
    "\r\n",
    "$$\r\n",
    "f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\r\n",
    "$$\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 12. Multinomial Distribution <a name=\"Multinomial\"></a>\r\n",
    "\r\n",
    "The **Multinomial Distribution** is a generalization of the **Binomial Distribution**. It describes the probabilities of the counts of different categories when performing experiments with more than two possible outcomes. It is useful for categorical outcomes like rolling a die or selecting multiple items from a set of categories.\r\n",
    "\r\n",
    "The probability mass function (PMF) for the multinomial distribution is:\r\n",
    "\r\n",
    "$$\r\n",
    "P(X_1 = x_1, X_2 = x_2, ..., X_k = x_k) = \\frac{n!}{x_1! x_2! ... x_k!} p_1^{x_1} p_2^{x_2} ... p_k^{x_k}\r\n",
    "$$\r\n",
    "\r\n",
    "Where:\r\n",
    "- $n$ is the total number of trials\r\n",
    "- $p_1, p_2, ..., p_k$ are the probabilities of each category\r\n",
    "- $x_1, x_2, ..., x_k$ are the counts of each category\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 13. Dirichlet Distribution <a name=\"Dirichlet\"></a>\r\n",
    "\r\n",
    "The **Dirichlet Distribution** is a multivariate generalization of the **Beta Distribution**. It is often used as a prior distribution in **Bayesian inference** when modeling probabilities of multiple categories or events. \r\n",
    "\r\n",
    "The probability density function (PDF) of the Dirichlet distribution is:\r\n",
    "\r\n",
    "$$\r\n",
    "f(x_1, x_2, ..., x_k) = \\frac{1}{B(\\alpha)} \\prod_{i=1}^{k} x_i^{\\alpha_i - 1}\r\n",
    "$$\r\n",
    "\r\n",
    "Where:\r\n",
    "- $\\alpha_i$ are the parameters of the distribution\r\n",
    "- $B(\\alpha)$ is the Beta function\r\n",
    "\r\n",
    "The Dirichlet distribution is widely used in **topic modeling** and **Bayesian mixture models**.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 14. Jointly Normal Distribution <a name=\"JointlyNormal\"></a>\r\n",
    "\r\n",
    "A set of random variables is **jointly normal** if every linear combination of these variables follows a normal distribution. That means if we take any linear combination of these variables, it will result in a normally distributed variable.\r\n",
    "\r\n",
    "For example, if $\\mathbf{X} = [X_1, X_2]^T$ is jointly normal, then for any constants $a_1$ and $a_2$:\r\n",
    "\r\n",
    "$$\r\n",
    "a_1 X_1 + a_2 X_2 \\sim N(\\mu_1 a_1 + \\mu_2 a_2, \\sigma_1^2 a_1^2 + \\sigma_2^2 a_2^2 + 2a_1 a_2 Cov(X_1, X_2))\r\n",
    "$$\r\n",
    "\r\n",
    "The joint normality property helps in simplifying multivariate analysis and is widely used in regression analysis, portfolio theory, and other fields."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
